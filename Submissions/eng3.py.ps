%!PS-Adobe-3.0
%%Title: HW3//eng3.py
%%For: eeng
%%Creator: VIM - Vi IMproved 8.2 (2019 Dec 12)
%%CreationDate: Thu Sep 26 17:21:32 2024
%%DocumentData: Clean8Bit
%%Orientation: Portrait
%%Pages: (atend)
%%PageOrder: Ascend
%%BoundingBox: 59 49 564 800
%%DocumentMedia: A4 595 842 0 () ()
%%DocumentNeededResources: font Courier
%%+ font Courier-Bold
%%+ font Courier-Oblique
%%+ font Courier-BoldOblique
%%DocumentSuppliedResources: procset VIM-Prolog 1.4 1
%%+ encoding VIM-latin1 1.0 0
%%Requirements: duplex collate color
%%EndComments
%%BeginDefaults
%%PageResources: font Courier
%%+ font Courier-Bold
%%+ font Courier-Oblique
%%+ font Courier-BoldOblique
%%PageMedia: A4
%%EndDefaults
%%BeginProlog
%%BeginResource: procset VIM-Prolog
%%BeginDocument: /usr/share/vim/vim82/print/prolog.ps
%!PS-Adobe-3.0 Resource-ProcSet
%%Title: VIM-Prolog
%%Version: 1.4 1
%%EndComments
% Editing of this file is NOT RECOMMENDED.  You run a very good risk of causing
% all PostScript printing from VIM failing if you do.  PostScript is not called
% a write-only language for nothing!
/packedarray where not{userdict begin/setpacking/pop load def/currentpacking
false def end}{pop}ifelse/CP currentpacking def true setpacking
/bd{bind def}bind def/ld{load def}bd/ed{exch def}bd/d/def ld
/db{dict begin}bd/cde{currentdict end}bd
/T true d/F false d
/SO null d/sv{/SO save d}bd/re{SO restore}bd
/L2 systemdict/languagelevel 2 copy known{get exec}{pop pop 1}ifelse 2 ge d
/m/moveto ld/s/show ld /ms{m s}bd /g/setgray ld/r/setrgbcolor ld/sp{showpage}bd
/gs/gsave ld/gr/grestore ld/cp/currentpoint ld
/ul{gs UW setlinewidth cp UO add 2 copy newpath m 3 1 roll add exch lineto
stroke gr}bd
/bg{gs r cp BO add 4 -2 roll rectfill gr}bd
/sl{90 rotate 0 exch translate}bd
L2{
/sspd{mark exch{setpagedevice}stopped cleartomark}bd
/nc{1 db/NumCopies ed cde sspd}bd
/sps{3 db/Orientation ed[3 1 roll]/PageSize ed/ImagingBBox null d cde sspd}bd
/dt{2 db/Tumble ed/Duplex ed cde sspd}bd
/c{1 db/Collate ed cde sspd}bd
}{
/nc{/#copies ed}bd
/sps{statusdict/setpage get exec}bd
/dt{statusdict/settumble 2 copy known{get exec}{pop pop pop}ifelse
statusdict/setduplexmode 2 copy known{get exec}{pop pop pop}ifelse}bd
/c{pop}bd
}ifelse
/ffs{findfont exch scalefont d}bd/sf{setfont}bd
/ref{1 db findfont dup maxlength dict/NFD ed{exch dup/FID ne{exch NFD 3 1 roll
put}{pop pop}ifelse}forall/Encoding findresource dup length 256 eq{NFD/Encoding
3 -1 roll put}{pop}ifelse NFD dup/FontType get 3 ne{/CharStrings}{/CharProcs}
ifelse 2 copy known{2 copy get dup maxlength dict copy[/questiondown/space]{2
copy known{2 copy get 2 index/.notdef 3 -1 roll put pop exit}if pop}forall put
}{pop pop}ifelse dup NFD/FontName 3 -1 roll put NFD definefont pop end}bd
CP setpacking
(\004)cvn{}bd
% vim:ff=unix:
%%EOF
%%EndDocument
%%EndResource
%%BeginResource: encoding VIM-latin1
%%BeginDocument: /usr/share/vim/vim82/print/latin1.ps
%!PS-Adobe-3.0 Resource-Encoding
%%Title: VIM-latin1
%%Version: 1.0 0
%%EndComments
/VIM-latin1[
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/space /exclam /quotedbl /numbersign /dollar /percent /ampersand /quotesingle
/parenleft /parenright /asterisk /plus /comma /minus /period /slash
/zero /one /two /three /four /five /six /seven
/eight /nine /colon /semicolon /less /equal /greater /question
/at /A /B /C /D /E /F /G
/H /I /J /K /L /M /N /O
/P /Q /R /S /T /U /V /W
/X /Y /Z /bracketleft /backslash /bracketright /asciicircum /underscore
/grave /a /b /c /d /e /f /g
/h /i /j /k /l /m /n /o
/p /q /r /s /t /u /v /w
/x /y /z /braceleft /bar /braceright /asciitilde /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/space /exclamdown /cent /sterling /currency /yen /brokenbar /section
/dieresis /copyright /ordfeminine /guillemotleft /logicalnot /hyphen /registered /macron
/degree /plusminus /twosuperior /threesuperior /acute /mu /paragraph /periodcentered
/cedilla /onesuperior /ordmasculine /guillemotright /onequarter /onehalf /threequarters /questiondown
/Agrave /Aacute /Acircumflex /Atilde /Adieresis /Aring /AE /Ccedilla
/Egrave /Eacute /Ecircumflex /Edieresis /Igrave /Iacute /Icircumflex /Idieresis
/Eth /Ntilde /Ograve /Oacute /Ocircumflex /Otilde /Odieresis /multiply
/Oslash /Ugrave /Uacute /Ucircumflex /Udieresis /Yacute /Thorn /germandbls
/agrave /aacute /acircumflex /atilde /adieresis /aring /ae /ccedilla
/egrave /eacute /ecircumflex /edieresis /igrave /iacute /icircumflex /idieresis
/eth /ntilde /ograve /oacute /ocircumflex /otilde /odieresis /divide
/oslash /ugrave /uacute /ucircumflex /udieresis /yacute /thorn /ydieresis]
/Encoding defineresource pop
% vim:ff=unix:
%%EOF
%%EndDocument
%%EndResource
%%EndProlog
%%BeginSetup
595 842 0 sps
1 nc
T F dt
T c
%%IncludeResource: font Courier
/_F0 /VIM-latin1 /Courier ref
/F0 10 /_F0 ffs
%%IncludeResource: font Courier-Bold
/_F1 /VIM-latin1 /Courier-Bold ref
/F1 10 /_F1 ffs
%%IncludeResource: font Courier-Oblique
/_F2 /VIM-latin1 /Courier-Oblique ref
/F2 10 /_F2 ffs
%%IncludeResource: font Courier-BoldOblique
/_F3 /VIM-latin1 /Courier-BoldOblique ref
/F3 10 /_F3 ffs
/UO -1 d
/UW 0.5 d
/BO -2.5 d
%%EndSetup
%%Page: 1 1
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(HW3//eng3.py                                                                  Page 1)59.5 792.4 ms
F0 sf
0.753 0 0 r
(#!/bin/env python)59.5 772.4 ms
0.753 0 0.753 r
(from)59.5 752.4 ms
0 g
( typing )s
0.753 0 0.753 r
(import)s
0 g
( Any)s
0.753 0 0.753 r
(import)59.5 742.4 ms
0 g
( tensorflow )s
0 0.502 0 r
(as)s
0 g
( tf)s
0 0.502 0 r
(class)59.5 712.4 ms
0 g
( )s
0.502 0.502 0 r
(Linear)s
0 g
(\(tf.Module\):)s
(    )59.5 702.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__init__)s
0 g
(\(self, num_inputs, num_outputs, bias=)s
0.502 0.502 0 r
(True)s
0 g
(\):)s
(        rng = tf.random.get_global_generator\(\))59.5 692.4 ms
(        stddev = tf.cast\(tf.math.sqrt\()59.5 672.4 ms
0 0 0.753 r
(2)s
0 g
( / \(num_inputs + num_outputs\)\), dtype = tf.fl)s
(oat32\))59.5 662.4 ms
(        self.w = tf.Variable\()59.5 642.4 ms
(            rng.normal\(shape=[num_inputs, num_outputs], stddev=stddev\),)59.5 632.4 ms
(            trainable=)59.5 622.4 ms
0.502 0.502 0 r
(True)s
0 g
(,)s
(            name=)59.5 612.4 ms
0 0 0.753 r
("Linear/w")s
0 g
(,)s
(        \))59.5 602.4 ms
(        self.bias = bias)59.5 582.4 ms
(        )59.5 562.4 ms
0 0.502 0 r
(if)s
0 g
( self.bias:)s
(            self.b = tf.Variable\()59.5 552.4 ms
(                tf.zeros\()59.5 542.4 ms
(                    shape=[)59.5 532.4 ms
0 0 0.753 r
(1)s
0 g
(, num_outputs],)s
(                \),)59.5 522.4 ms
(                trainable=)59.5 512.4 ms
0.502 0.502 0 r
(True)s
0 g
(,)s
(                name=)59.5 502.4 ms
0 0 0.753 r
("Linear/b")s
0 g
(,)s
(            \))59.5 492.4 ms
(    )59.5 472.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__call__)s
0 g
(\(self, x\):)s
(        z = x @ self.w)59.5 462.4 ms
(        )59.5 442.4 ms
0 0.502 0 r
(if)s
0 g
( self.bias:)s
(            z += self.b)59.5 432.4 ms
(        )59.5 412.4 ms
0 0.502 0 r
(return)s
0 g
( z)s
(    )59.5 402.4 ms
0 0.502 0 r
(class)59.5 392.4 ms
0 g
( )s
0.502 0.502 0 r
(Conv2d)s
0 g
(\(tf.Module\):)s
(    )59.5 382.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__init__)s
0 g
(\(self, k, in_channels, out_channels, stride = )s
0 0 0.753 r
(1)s
0 g
(, dropout_prob = )s
0 0 0.753 r
(0.2)s
0 g
(,)s
( activation = tf.identity\):)59.5 372.4 ms
(        self.dropout_prob = dropout_prob)59.5 362.4 ms
(        self.k = k)59.5 352.4 ms
(        rng = tf.random.get_global_generator\(\))59.5 342.4 ms
(        stddev = tf.cast\(tf.math.sqrt\()59.5 322.4 ms
0 0 0.753 r
(1)s
0 g
( / k\), dtype = tf.float32\))s
(        self.stride = stride)59.5 312.4 ms
(        self.activation = activation)59.5 302.4 ms
(        self.kernel = tf.Variable\()59.5 292.4 ms
(            )59.5 282.4 ms
0.753 0 0 r
(#[filter_height, filter_width, in_channels, out_channels])s
0 g
(            )59.5 272.4 ms
0.753 0 0 r
(# tf.ones\(shape=[self.k, self.k, in_channels, out_channels]\),)s
0 g
(            rng.normal\(shape=[self.k, self.k, in_channels, out_channels], stddev= st)59.5 262.4 ms
(ddev\),)59.5 252.4 ms
(            trainable=)59.5 242.4 ms
0.502 0.502 0 r
(True)s
0 g
(,)s
(            name=)59.5 232.4 ms
0 0 0.753 r
("Conv2d/kernel")s
0 g
(,)s
(        \))59.5 222.4 ms
(    )59.5 202.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__call__)s
0 g
(\(self, x\):)s
(        z = tf.nn.conv2d\(x, self.kernel, strides=[)59.5 192.4 ms
0 0 0.753 r
(1)s
0 g
(, self.stride, self.stride, )s
0 0 0.753 r
(1)s
0 g
(], p)s
(adding = )59.5 182.4 ms
0 0 0.753 r
("SAME")s
0 g
(\))s
(        )59.5 172.4 ms
0.753 0 0 r
(# apply the activation function)s
0 g
(        z = self.activation\(z\))59.5 162.4 ms
(        )59.5 152.4 ms
0.753 0 0 r
(# # apply dropout)s
0 g
(        rng = tf.random.get_global_generator\(\))59.5 142.4 ms
(        dropout_vec = tf.cast\(tf.where\(rng.uniform\(shape = z.shape, minval = )59.5 132.4 ms
0 0 0.753 r
(0)s
0 g
(, maxv)s
(al = )59.5 122.4 ms
0 0 0.753 r
(1)s
0 g
(\) < \()s
0 0 0.753 r
(1)s
0 g
(-self.dropout_prob\), )s
0 0 0.753 r
(1)s
0 g
(, )s
0 0 0.753 r
(0)s
0 g
(\), tf.float32\))s
(        z = tf.math.multiply\(z, dropout_vec\) / \()59.5 112.4 ms
0 0 0.753 r
(1)s
0 g
(-self.dropout_prob\))s
(        )59.5 102.4 ms
0 0.502 0 r
(return)s
0 g
( z)s
(    )59.5 92.4 ms
0.753 0 0 r
(# Pooling class not used, but I probably should have. )59.5 82.4 ms
0 0.502 0 r
(class)59.5 72.4 ms
0 g
( )s
0.502 0.502 0 r
(AvgPooling)s
0 g
(\(tf.Module\):)s
(    )59.5 62.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__init__)s
0 g
(\(self, k, in_channels, out_channels\):)s
(        self.k = k)59.5 52.4 ms
re sp
%%PageTrailer
%%Page: 2 2
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(HW3//eng3.py                                                                  Page 2)59.5 792.4 ms
F0 sf
(        )59.5 772.4 ms
0.753 0 0 r
(# make an averaging kernel in the pooling layer, do not make it trainable)s
0 g
(        self.kernel = tf.Variable\()59.5 762.4 ms
(            tf.ones\(shape=[self.k, self.k, in_channels, out_channels]\)/k**)59.5 752.4 ms
0 0 0.753 r
(2)s
0 g
(,)s
(            )59.5 742.4 ms
0.753 0 0 r
(# trainable=True,)s
0 g
(            name=)59.5 732.4 ms
0 0 0.753 r
("AvgPooling/kernel")s
0 g
(,)s
(        \))59.5 722.4 ms
(    )59.5 702.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__call__)s
0 g
(\(self, x\):)s
(        )59.5 692.4 ms
0.753 0 0 r
(# perform the convolution on the batch)s
0 g
(        z = tf.nn.conv2d\(x, self.kernel, strides=[)59.5 682.4 ms
0 0 0.753 r
(1)s
0 g
(, self.k, self.k, )s
0 0 0.753 r
(1)s
0 g
(], padding = )s
0 0 0.753 r
(")s
(SAME")59.5 672.4 ms
0 g
(\))s
(        )59.5 662.4 ms
0 0.502 0 r
(return)s
0 g
( z)s
0 0.502 0 r
(class)59.5 642.4 ms
0 g
( )s
0.502 0.502 0 r
(Classifier)s
0 g
(\(tf.Module\):)s
(    )59.5 632.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__init__)s
0 g
(\(self, input_depth, layer_depths, layer_kernel_sizes, num_classes, n)s
(um_conv_layers, strides = )59.5 622.4 ms
0.502 0.502 0 r
(None)s
0 g
(, dropout_prob = )s
0 0 0.753 r
(0.1)s
0 g
(\):)s
(        )59.5 612.4 ms
0 0.502 0 r
(if)s
0 g
( strides )s
0 0.502 0 r
(is)s
0 g
( )s
0.502 0.502 0 r
(None)s
0 g
(: strides = tf.ones\(shape = [num_conv_layers]\))s
(        )59.5 592.4 ms
0.753 0 0 r
(#should probably throw an error if num_conv_layers doesn't match length of l)s
(ayer_depths or layer_kernel_sizes)59.5 582.4 ms
0 g
(        self.input_depth = input_depth)59.5 562.4 ms
(        self.layer_depths = layer_depths)59.5 552.4 ms
(        self.layer_kernel_sizes = layer_kernel_sizes)59.5 542.4 ms
(        self.num_classes = num_classes)59.5 532.4 ms
(        )59.5 522.4 ms
0.753 0 0 r
(# def __init__\(self, k, in_channels, out_channels, stride = 1, dropout_prob )s
(= 0.1, activation = tf.identity\):)59.5 512.4 ms
0 g
(        )59.5 502.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        self.conv_layers = [])59.5 482.4 ms
(        )59.5 472.4 ms
0 0.502 0 r
(for)s
0 g
( i )s
0 0.502 0 r
(in)s
0 g
( )s
0.502 0.502 0 r
(range)s
0 g
(\(num_conv_layers\):)s
(            )59.5 462.4 ms
0 0.502 0 r
(if)s
0 g
( i == )s
0 0 0.753 r
(0)s
0 g
(:)s
(                self.conv_layers.append\(Conv2d\(layer_kernel_sizes[i][)59.5 452.4 ms
0 0 0.753 r
(0)s
0 g
(], input_depth)s
(, layer_depths[i], strides[i], dropout_prob= dropout_prob, activation=tf.nn.leaky_re)59.5 442.4 ms
(lu\)\))59.5 432.4 ms
(            )59.5 422.4 ms
0 0.502 0 r
(else)s
0 g
(:)s
(                self.conv_layers.append\(Conv2d\(layer_kernel_sizes[i][)59.5 412.4 ms
0 0 0.753 r
(0)s
0 g
(], layer_depth)s
(s[i-)59.5 402.4 ms
0 0 0.753 r
(1)s
0 g
(], layer_depths[i], strides[i], dropout_prob= dropout_prob, activation=tf.nn.le)s
(aky_relu\)\))59.5 392.4 ms
(        self.output_layer = Linear\()59.5 382.4 ms
0 0 0.753 r
(28)s
0 g
(*)s
0 0 0.753 r
(28)s
0 g
(*layer_depths[-)s
0 0 0.753 r
(1)s
0 g
(], self.num_classes\))s
(        )59.5 372.4 ms
0.753 0 0 r
(# self.output_layer = Linear\(num_classes\))s
0 g
(    )59.5 362.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__call__)s
0 g
(\(self, x\):)s
(        )59.5 352.4 ms
0.753 0 0 r
(# conv_layers)s
0 g
(        conv_output = tf.reshape\(x, [x.shape[)59.5 342.4 ms
0 0 0.753 r
(0)s
0 g
(], x.shape[)s
0 0 0.753 r
(1)s
0 g
(], x.shape[)s
0 0 0.753 r
(2)s
0 g
(], self.input_)s
(depth]\))59.5 332.4 ms
(        )59.5 322.4 ms
0 0.502 0 r
(for)s
0 g
( i )s
0 0.502 0 r
(in)s
0 g
( )s
0.502 0.502 0 r
(range)s
0 g
(\()s
0.502 0.502 0 r
(len)s
0 g
(\(self.conv_layers\)\):)s
(            )59.5 312.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(            conv_output = self.conv_layers[i]\(conv_output\))59.5 302.4 ms
(        )59.5 282.4 ms
0.753 0 0 r
(#pooling)s
0 g
(        )59.5 272.4 ms
0.753 0 0 r
(# flatten conv output)s
0 g
(        )59.5 262.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        out_flat = tf.reshape\(conv_output, [x.shape[)59.5 252.4 ms
0 0 0.753 r
(0)s
0 g
(], -)s
0 0 0.753 r
(1)s
0 g
(]\))s
(        )59.5 242.4 ms
0.753 0 0 r
(# get length of flattened output)s
0 g
(        )59.5 232.4 ms
0.753 0 0 r
(# output_len = tf.cast\(tf.size\(out_flat\)/x.shape[0], tf.int64\))s
0 g
(        )59.5 222.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        )59.5 202.4 ms
(        )59.5 192.4 ms
0.753 0 0 r
(# out_flat = tf.reshape\(out_flat, [-1, out_flat.shape[-1]]\))s
0 g
(        z = self.output_layer\(out_flat\))59.5 182.4 ms
(        z = tf.nn.softmax\(z\))59.5 172.4 ms
(        )59.5 162.4 ms
0 0.502 0 r
(return)s
0 g
( z)s
(        )59.5 142.4 ms
0 0.502 0 r
(def)59.5 122.4 ms
0 g
( )s
0.502 0.502 0 r
(grad_update)s
0 g
(\(step_size, variables, grads\):)s
(    )59.5 112.4 ms
0 0.502 0 r
(for)s
0 g
( var, grad )s
0 0.502 0 r
(in)s
0 g
( )s
0.502 0.502 0 r
(zip)s
0 g
(\(variables, grads\):)s
(        var.assign_sub\(step_size * grad\))59.5 102.4 ms
0 0.502 0 r
(if)59.5 72.4 ms
0 g
( __name__ == )s
0 0 0.753 r
("__main__")s
0 g
(:)s
(    )59.5 62.4 ms
0.753 0 0.753 r
(import)s
0 g
( argparse)s
re sp
%%PageTrailer
%%Page: 3 3
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(HW3//eng3.py                                                                  Page 3)59.5 792.4 ms
F0 sf
(    )59.5 772.4 ms
0.753 0 0.753 r
(from)s
0 g
( pathlib )s
0.753 0 0.753 r
(import)s
0 g
( Path)s
(    )59.5 752.4 ms
0.753 0 0.753 r
(import)s
0 g
( matplotlib.pyplot )s
0 0.502 0 r
(as)s
0 g
( plt)s
(    )59.5 742.4 ms
0.753 0 0.753 r
(import)s
0 g
( yaml)s
(    )59.5 732.4 ms
0.753 0 0.753 r
(import)s
0 g
( numpy )s
0 0.502 0 r
(as)s
0 g
( np)s
(    )59.5 712.4 ms
0.753 0 0.753 r
(from)s
0 g
( tqdm )s
0.753 0 0.753 r
(import)s
0 g
( trange)s
(    )59.5 702.4 ms
0.753 0 0.753 r
(from)s
0 g
( mnist )s
0.753 0 0.753 r
(import)s
0 g
( MNIST)s
(    )59.5 692.4 ms
0.753 0 0.753 r
(from)s
0 g
( sklearn.preprocessing )s
0.753 0 0.753 r
(import)s
0 g
( OneHotEncoder)s
(    )59.5 682.4 ms
0.753 0 0.753 r
(from)s
0 g
( sklearn.model_selection )s
0.753 0 0.753 r
(import)s
0 g
( train_test_split)s
(    parser = argparse.ArgumentParser\()59.5 662.4 ms
(        prog=)59.5 652.4 ms
0 0 0.753 r
("Linear")s
0 g
(,)s
(        description=)59.5 642.4 ms
0 0 0.753 r
("Fits a linear model to some data, given a config")s
0 g
(,)s
(    \))59.5 632.4 ms
(    parser.add_argument\()59.5 612.4 ms
0 0 0.753 r
("-c")s
0 g
(, )s
0 0 0.753 r
("--config")s
0 g
(, )s
0.502 0.502 0 r
(type)s
0 g
(=Path, default=Path\()s
0 0 0.753 r
("config.yaml")s
0 g
(\)\))s
(    args = parser.parse_args\(\))59.5 602.4 ms
(    config = yaml.safe_load\(args.config.read_text\(\)\))59.5 582.4 ms
(    rng = tf.random.get_global_generator\(\))59.5 562.4 ms
(    rng.reset_from_seed\()59.5 552.4 ms
0 0 0.753 r
(0x43966E87BD57227011B5B03B58785EC1)s
0 g
(\))s
(    num_samples = config[)59.5 532.4 ms
0 0 0.753 r
("data")s
0 g
(][)s
0 0 0.753 r
("num_samples")s
0 g
(])s
(    num_inputs = )59.5 522.4 ms
0 0 0.753 r
(1)s
0 g
(    num_outputs = )59.5 512.4 ms
0 0 0.753 r
(1)s
0 g
(    enc = OneHotEncoder\(handle_unknown=)59.5 492.4 ms
0 0 0.753 r
("ignore")s
0 g
(\))s
(    mndata = MNIST\()59.5 472.4 ms
0 0 0.753 r
('MNIST_dataset')s
0 g
(\))s
(    images_trainval, labels_trainval = mndata.load_training\(\))59.5 452.4 ms
(    images_test, labels_test = mndata.load_testing\(\))59.5 442.4 ms
(    )59.5 422.4 ms
0.753 0 0 r
(# format is list of arrays, convert to array first and then to tensor)s
0 g
(    images_trainval = np.array\(images_trainval\))59.5 402.4 ms
(    images_test = np.array\(images_test\))59.5 392.4 ms
(    labels_trainval = np.array\(labels_trainval\))59.5 372.4 ms
(    labels_test = np.array\(labels_test\)    )59.5 362.4 ms
(    )59.5 332.4 ms
0.753 0 0 r
(# train/val split)s
0 g
(    arrays_train, arrays_val, labels_train, labels_val = train_test_split\(images_tra)59.5 322.4 ms
(inval, labels_trainval, test_size = )59.5 312.4 ms
0 0 0.753 r
(0.3)s
0 g
(, random_state = )s
0 0 0.753 r
(42)s
0 g
(\))s
(    )59.5 292.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(    images_train = tf.convert_to_tensor\(arrays_train.reshape\(-)59.5 272.4 ms
0 0 0.753 r
(1)s
0 g
(, )s
0 0 0.753 r
(28)s
0 g
(, )s
0 0 0.753 r
(28)s
0 g
(\), dtype = tf)s
(.float32\))59.5 262.4 ms
(    images_val = tf.convert_to_tensor\(arrays_val.reshape\(-)59.5 252.4 ms
0 0 0.753 r
(1)s
0 g
(, )s
0 0 0.753 r
(28)s
0 g
(, )s
0 0 0.753 r
(28)s
0 g
(\), dtype = tf.flo)s
(at32\))59.5 242.4 ms
(    images_test = tf.convert_to_tensor\(images_test.reshape\(-)59.5 232.4 ms
0 0 0.753 r
(1)s
0 g
(, )s
0 0 0.753 r
(28)s
0 g
(, )s
0 0 0.753 r
(28)s
0 g
(\), dtype = tf.f)s
(loat32\))59.5 222.4 ms
(    )59.5 202.4 ms
0.753 0 0 r
(# One-hot encoding to make compatible with )s
0 g
(    labels_train = tf.one_hot\(labels_train, )59.5 192.4 ms
0 0 0.753 r
(10)s
0 g
(\))s
(    labels_val = tf.one_hot\(labels_val, )59.5 182.4 ms
0 0 0.753 r
(10)s
0 g
(\))s
(    labels_test = tf.one_hot\(labels_test, )59.5 172.4 ms
0 0 0.753 r
(10)s
0 g
(\))s
(    )59.5 152.4 ms
0.753 0 0 r
(#def __init__\(self, input_depth, layer_depths, layer_kernel_sizes, num_classes, )s
(num_conv_layers, strides = None\):)59.5 142.4 ms
0 g
(    classifier = Classifier\()59.5 132.4 ms
0 0 0.753 r
(1)s
0 g
(, [)s
0 0 0.753 r
(2)s
0 g
(, )s
0 0 0.753 r
(2)s
0 g
(, )s
0 0 0.753 r
(3)s
0 g
(], [[)s
0 0 0.753 r
(3)s
0 g
(, )s
0 0 0.753 r
(3)s
0 g
(], [)s
0 0 0.753 r
(2)s
0 g
(, )s
0 0 0.753 r
(2)s
0 g
(], [)s
0 0 0.753 r
(2)s
0 g
(, )s
0 0 0.753 r
(2)s
0 g
(]], )s
0 0 0.753 r
(10)s
0 g
(, )s
0 0 0.753 r
(3)s
0 g
(, dropout_p)s
(rob= )59.5 122.4 ms
0 0 0.753 r
(0.1)s
0 g
(\))s
(    )59.5 102.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(    num_iters = config[)59.5 92.4 ms
0 0 0.753 r
("learning")s
0 g
(][)s
0 0 0.753 r
("num_iters")s
0 g
(])s
(    step_size = config[)59.5 82.4 ms
0 0 0.753 r
("learning")s
0 g
(][)s
0 0 0.753 r
("step_size")s
0 g
(])s
(    decay_rate = config[)59.5 72.4 ms
0 0 0.753 r
("learning")s
0 g
(][)s
0 0 0.753 r
("decay_rate")s
0 g
(])s
(    batch_size = config[)59.5 62.4 ms
0 0 0.753 r
("learning")s
0 g
(][)s
0 0 0.753 r
("batch_size")s
0 g
(])s
(    gamma = config[)59.5 52.4 ms
0 0 0.753 r
("learning")s
0 g
(][)s
0 0 0.753 r
("weight_decay")s
0 g
(])s
re sp
%%PageTrailer
%%Page: 4 4
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(HW3//eng3.py                                                                  Page 4)59.5 792.4 ms
F0 sf
(    refresh_rate = config[)59.5 772.4 ms
0 0 0.753 r
("display")s
0 g
(][)s
0 0 0.753 r
("refresh_rate")s
0 g
(])s
(    bar = trange\(num_iters\))59.5 752.4 ms
(    cce = tf.keras.losses.CategoricalCrossentropy\(\))59.5 742.4 ms
(    beta_1 = )59.5 732.4 ms
0 0 0.753 r
(0.9)s
0 g
(    beta_2 = )59.5 722.4 ms
0 0 0.753 r
(0.999)s
0 g
(    )59.5 712.4 ms
0.753 0 0 r
(# Initialize 1st and 2nd moment vectors)s
0 g
(    m = [tf.zeros\(classifier.trainable_variables[i].shape, dtype = )59.5 702.4 ms
0 0 0.753 r
('float32')s
0 g
(\) )s
0 0.502 0 r
(for)s
0 g
( i )s
0 0.502 0 r
(in)59.5 692.4 ms
0 g
( )s
0.502 0.502 0 r
(range)s
0 g
(\()s
0.502 0.502 0 r
(len)s
0 g
(\(classifier.trainable_variables\)\)])s
(    v = [tf.zeros\(classifier.trainable_variables[i].shape, dtype = )59.5 682.4 ms
0 0 0.753 r
('float32')s
0 g
(\) )s
0 0.502 0 r
(for)s
0 g
( i )s
0 0.502 0 r
(in)59.5 672.4 ms
0 g
( )s
0.502 0.502 0 r
(range)s
0 g
(\()s
0.502 0.502 0 r
(len)s
0 g
(\(classifier.trainable_variables\)\)])s
(    )59.5 662.4 ms
0 0.502 0 r
(for)s
0 g
( i )s
0 0.502 0 r
(in)s
0 g
( bar:)s
(        )59.5 652.4 ms
0 0.502 0 r
(if)s
0 g
( i == )s
0 0 0.753 r
(5000)s
0 g
(:)s
(            step_size = step_size/)59.5 642.4 ms
0 0 0.753 r
(50)s
0 g
(        )59.5 632.4 ms
0.753 0 0 r
(#     beta_1 = 0.99)s
0 g
(        )59.5 622.4 ms
0.753 0 0 r
(#     beta_2 = 0.9999)s
0 g
(            )59.5 612.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        )59.5 602.4 ms
0.753 0 0 r
(# elif i == 7000:)s
0 g
(        )59.5 592.4 ms
0.753 0 0 r
(#     step_size = step_size/10)s
0 g
(            )59.5 582.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        batch_indices = rng.uniform\()59.5 572.4 ms
(            shape=[batch_size], maxval=num_samples, dtype=tf.int32)59.5 562.4 ms
(        \))59.5 552.4 ms
(        )59.5 532.4 ms
0 0.502 0 r
(with)s
0 g
( tf.GradientTape\(\) )s
0 0.502 0 r
(as)s
0 g
( tape:)s
(            x_batch = tf.gather\(images_train, batch_indices\))59.5 522.4 ms
(            y_batch = tf.gather\(labels_train, batch_indices\))59.5 512.4 ms
(            )59.5 492.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(            y_hat = classifier\(x_batch\))59.5 472.4 ms
(            loss = cce\(y_batch, y_hat\))59.5 462.4 ms
(            )59.5 452.4 ms
0 0.502 0 r
(for)s
0 g
( var )s
0 0.502 0 r
(in)s
0 g
( classifier.trainable_variables:)s
(                loss += gamma * tf.math.reduce_sum\(tf.multiply\(tf.reshape\(var, [)59.5 442.4 ms
0 0 0.753 r
(1)s
0 g
(, -)s
0 0 0.753 r
(1)59.5 432.4 ms
0 g
(]\), tf.reshape\(var, [)s
0 0 0.753 r
(1)s
0 g
(, -)s
0 0 0.753 r
(1)s
0 g
(]\)\)\))s
(        grads = tape.gradient\(loss, classifier.trainable_variables\))59.5 422.4 ms
(        )59.5 412.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        )59.5 402.4 ms
0.753 0 0 r
(#Implementing Adam)s
0 g
(        )59.5 392.4 ms
(        )59.5 382.4 ms
0.753 0 0 r
(# w = gamma/step_size)s
0 g
(        )59.5 372.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        m = )59.5 362.4 ms
0.502 0.502 0 r
(tuple)s
0 g
(\()s
0.502 0.502 0 r
(map)s
0 g
(\()s
0.502 0.502 0 r
(sum)s
0 g
(, )s
0.502 0.502 0 r
(zip)s
0 g
(\()s
0.502 0.502 0 r
(tuple)s
0 g
(\([\(beta_1\)*m_i )s
0 0.502 0 r
(for)s
0 g
( m_i )s
0 0.502 0 r
(in)s
0 g
( m]\), )s
0.502 0.502 0 r
(tuple)s
0 g
(\([\()s
0 0 0.753 r
(1)s
0 g
(-beta_1\))s
(*grad )59.5 352.4 ms
0 0.502 0 r
(for)s
0 g
( grad )s
0 0.502 0 r
(in)s
0 g
( grads]\)\)\)\))s
(        grads_sq = [tf.math.multiply\(grad, grad\) )59.5 342.4 ms
0 0.502 0 r
(for)s
0 g
( grad )s
0 0.502 0 r
(in)s
0 g
( grads])s
(        v = )59.5 332.4 ms
0.502 0.502 0 r
(tuple)s
0 g
(\()s
0.502 0.502 0 r
(map)s
0 g
(\()s
0.502 0.502 0 r
(sum)s
0 g
(, )s
0.502 0.502 0 r
(zip)s
0 g
(\()s
0.502 0.502 0 r
(tuple)s
0 g
(\([\(beta_2\)*v_i )s
0 0.502 0 r
(for)s
0 g
( v_i )s
0 0.502 0 r
(in)s
0 g
( v]\), )s
0.502 0.502 0 r
(tuple)s
0 g
(\([\()s
0 0 0.753 r
(1)s
0 g
(-beta_2\))s
(*grad )59.5 322.4 ms
0 0.502 0 r
(for)s
0 g
( grad )s
0 0.502 0 r
(in)s
0 g
( grads_sq]\)\)\)\))s
(        )59.5 312.4 ms
(        m_hat = )59.5 302.4 ms
0.502 0.502 0 r
(tuple)s
0 g
(\([)s
0 0 0.753 r
(1)s
0 g
(/\()s
0 0 0.753 r
(1)s
0 g
(-beta_1**\(i+)s
0 0 0.753 r
(1)s
0 g
(\)\)*m_i )s
0 0.502 0 r
(for)s
0 g
( m_i )s
0 0.502 0 r
(in)s
0 g
( m]\))s
(        v_hat = )59.5 292.4 ms
0.502 0.502 0 r
(tuple)s
0 g
(\([)s
0 0 0.753 r
(1)s
0 g
(/\()s
0 0 0.753 r
(1)s
0 g
(-beta_2**\(i+)s
0 0 0.753 r
(1)s
0 g
(\)\)*v_i )s
0 0.502 0 r
(for)s
0 g
( v_i )s
0 0.502 0 r
(in)s
0 g
( v]\))s
(        )59.5 272.4 ms
0.753 0 0 r
(# Implement AdamW)s
0 g
(        grad_new = [tf.math.divide\(aItem, tf.math.sqrt\(bItem\)+\()59.5 262.4 ms
0 0 0.753 r
(1e-8)s
0 g
(\)\) + gamma * cIte)s
(m )59.5 252.4 ms
0 0.502 0 r
(for)s
0 g
( aItem, bItem, cItem )s
0 0.502 0 r
(in)s
0 g
( )s
0.502 0.502 0 r
(zip)s
0 g
(\(m_hat, v_hat, classifier.trainable_variables\)])s
(        )59.5 242.4 ms
0.753 0 0 r
(# grad_new = [tf.math.divide\(aItem, tf.math.sqrt\(bItem\)+\(1e-8\)\) for aItem, b)s
(Item in zip\(m_hat, v_hat\)])59.5 232.4 ms
0 g
(        )59.5 222.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        grad_update\(step_size, classifier.trainable_variables, grad_new\))59.5 212.4 ms
(        )59.5 192.4 ms
0 0.502 0 r
(if)s
0 g
( i % refresh_rate == \(refresh_rate - )s
0 0 0.753 r
(1)s
0 g
(\):)s
(            bar.set_description\()59.5 182.4 ms
(                f)59.5 172.4 ms
0 0 0.753 r
("Step {i}; Loss => {loss.numpy\(\):0.4f}, step_size => {step_size:0.4)s
(f}")59.5 162.4 ms
0 g
(            \))59.5 152.4 ms
(            bar.refresh\(\))59.5 142.4 ms
(    )59.5 132.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(    )59.5 112.4 ms
0.753 0 0 r
(# Accuracy calculation \(one-hot labels, input set, classifier\))s
0 g
(    )59.5 102.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(accuracy)s
0 g
(\(truth, )s
0.502 0.502 0 r
(set)s
0 g
(, classifier\):)s
(        preds = tf.argmax\(classifier\()59.5 92.4 ms
0.502 0.502 0 r
(set)s
0 g
(\), axis = )s
0 0 0.753 r
(1)s
0 g
(\))s
(        truth = tf.argmax\(truth, axis = )59.5 82.4 ms
0 0 0.753 r
(1)s
0 g
(\))s
(        accuracy = tf.math.count_nonzero\(tf.equal\(truth,preds\)\) / preds.shape[)59.5 72.4 ms
0 0 0.753 r
(0)s
0 g
(] * )s
0 0 0.753 r
(1)s
(00)59.5 62.4 ms
0 g
(        )59.5 52.4 ms
0 0.502 0 r
(return)s
0 g
( accuracy)s
re sp
%%PageTrailer
%%Page: 5 5
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(HW3//eng3.py                                                                  Page 5)59.5 792.4 ms
F0 sf
(    )59.5 762.4 ms
0.753 0 0 r
(# on validation data)s
0 g
(    )59.5 742.4 ms
0.753 0 0 r
(# validation accuracy 95.56%)s
0 g
(    )59.5 732.4 ms
0.502 0.502 0 r
(print)s
0 g
(\(accuracy\(labels_val, images_val, classifier\)\))s
(    )59.5 722.4 ms
(    )59.5 712.4 ms
0.753 0 0 r
(# train accuracy 96.8%)s
0 g
(    )59.5 702.4 ms
0.502 0.502 0 r
(print)s
0 g
(\(accuracy\(labels_train, images_train, classifier\)\))s
(    )59.5 682.4 ms
0.753 0 0 r
(# set a breakpoint so I can look at train/val accuracy without looking at test a)s
(ccuracy)59.5 672.4 ms
0 g
(    )59.5 662.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(    )59.5 642.4 ms
0.753 0 0 r
(# test accuracy 95.91%)s
0 g
(    )59.5 632.4 ms
0.502 0.502 0 r
(print)s
0 g
(\(accuracy\(labels_test, images_test, classifier\)\))s
re sp
%%PageTrailer
%%Trailer
%%Pages: 5
%%EOF
