%!PS-Adobe-3.0
%%Title: HW2//spirals.py
%%For: eeng
%%Creator: VIM - Vi IMproved 8.2 (2019 Dec 12)
%%CreationDate: Thu Sep 26 17:21:25 2024
%%DocumentData: Clean8Bit
%%Orientation: Portrait
%%Pages: (atend)
%%PageOrder: Ascend
%%BoundingBox: 59 49 564 800
%%DocumentMedia: A4 595 842 0 () ()
%%DocumentNeededResources: font Courier
%%+ font Courier-Bold
%%+ font Courier-Oblique
%%+ font Courier-BoldOblique
%%DocumentSuppliedResources: procset VIM-Prolog 1.4 1
%%+ encoding VIM-latin1 1.0 0
%%Requirements: duplex collate color
%%EndComments
%%BeginDefaults
%%PageResources: font Courier
%%+ font Courier-Bold
%%+ font Courier-Oblique
%%+ font Courier-BoldOblique
%%PageMedia: A4
%%EndDefaults
%%BeginProlog
%%BeginResource: procset VIM-Prolog
%%BeginDocument: /usr/share/vim/vim82/print/prolog.ps
%!PS-Adobe-3.0 Resource-ProcSet
%%Title: VIM-Prolog
%%Version: 1.4 1
%%EndComments
% Editing of this file is NOT RECOMMENDED.  You run a very good risk of causing
% all PostScript printing from VIM failing if you do.  PostScript is not called
% a write-only language for nothing!
/packedarray where not{userdict begin/setpacking/pop load def/currentpacking
false def end}{pop}ifelse/CP currentpacking def true setpacking
/bd{bind def}bind def/ld{load def}bd/ed{exch def}bd/d/def ld
/db{dict begin}bd/cde{currentdict end}bd
/T true d/F false d
/SO null d/sv{/SO save d}bd/re{SO restore}bd
/L2 systemdict/languagelevel 2 copy known{get exec}{pop pop 1}ifelse 2 ge d
/m/moveto ld/s/show ld /ms{m s}bd /g/setgray ld/r/setrgbcolor ld/sp{showpage}bd
/gs/gsave ld/gr/grestore ld/cp/currentpoint ld
/ul{gs UW setlinewidth cp UO add 2 copy newpath m 3 1 roll add exch lineto
stroke gr}bd
/bg{gs r cp BO add 4 -2 roll rectfill gr}bd
/sl{90 rotate 0 exch translate}bd
L2{
/sspd{mark exch{setpagedevice}stopped cleartomark}bd
/nc{1 db/NumCopies ed cde sspd}bd
/sps{3 db/Orientation ed[3 1 roll]/PageSize ed/ImagingBBox null d cde sspd}bd
/dt{2 db/Tumble ed/Duplex ed cde sspd}bd
/c{1 db/Collate ed cde sspd}bd
}{
/nc{/#copies ed}bd
/sps{statusdict/setpage get exec}bd
/dt{statusdict/settumble 2 copy known{get exec}{pop pop pop}ifelse
statusdict/setduplexmode 2 copy known{get exec}{pop pop pop}ifelse}bd
/c{pop}bd
}ifelse
/ffs{findfont exch scalefont d}bd/sf{setfont}bd
/ref{1 db findfont dup maxlength dict/NFD ed{exch dup/FID ne{exch NFD 3 1 roll
put}{pop pop}ifelse}forall/Encoding findresource dup length 256 eq{NFD/Encoding
3 -1 roll put}{pop}ifelse NFD dup/FontType get 3 ne{/CharStrings}{/CharProcs}
ifelse 2 copy known{2 copy get dup maxlength dict copy[/questiondown/space]{2
copy known{2 copy get 2 index/.notdef 3 -1 roll put pop exit}if pop}forall put
}{pop pop}ifelse dup NFD/FontName 3 -1 roll put NFD definefont pop end}bd
CP setpacking
(\004)cvn{}bd
% vim:ff=unix:
%%EOF
%%EndDocument
%%EndResource
%%BeginResource: encoding VIM-latin1
%%BeginDocument: /usr/share/vim/vim82/print/latin1.ps
%!PS-Adobe-3.0 Resource-Encoding
%%Title: VIM-latin1
%%Version: 1.0 0
%%EndComments
/VIM-latin1[
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/space /exclam /quotedbl /numbersign /dollar /percent /ampersand /quotesingle
/parenleft /parenright /asterisk /plus /comma /minus /period /slash
/zero /one /two /three /four /five /six /seven
/eight /nine /colon /semicolon /less /equal /greater /question
/at /A /B /C /D /E /F /G
/H /I /J /K /L /M /N /O
/P /Q /R /S /T /U /V /W
/X /Y /Z /bracketleft /backslash /bracketright /asciicircum /underscore
/grave /a /b /c /d /e /f /g
/h /i /j /k /l /m /n /o
/p /q /r /s /t /u /v /w
/x /y /z /braceleft /bar /braceright /asciitilde /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/space /exclamdown /cent /sterling /currency /yen /brokenbar /section
/dieresis /copyright /ordfeminine /guillemotleft /logicalnot /hyphen /registered /macron
/degree /plusminus /twosuperior /threesuperior /acute /mu /paragraph /periodcentered
/cedilla /onesuperior /ordmasculine /guillemotright /onequarter /onehalf /threequarters /questiondown
/Agrave /Aacute /Acircumflex /Atilde /Adieresis /Aring /AE /Ccedilla
/Egrave /Eacute /Ecircumflex /Edieresis /Igrave /Iacute /Icircumflex /Idieresis
/Eth /Ntilde /Ograve /Oacute /Ocircumflex /Otilde /Odieresis /multiply
/Oslash /Ugrave /Uacute /Ucircumflex /Udieresis /Yacute /Thorn /germandbls
/agrave /aacute /acircumflex /atilde /adieresis /aring /ae /ccedilla
/egrave /eacute /ecircumflex /edieresis /igrave /iacute /icircumflex /idieresis
/eth /ntilde /ograve /oacute /ocircumflex /otilde /odieresis /divide
/oslash /ugrave /uacute /ucircumflex /udieresis /yacute /thorn /ydieresis]
/Encoding defineresource pop
% vim:ff=unix:
%%EOF
%%EndDocument
%%EndResource
%%EndProlog
%%BeginSetup
595 842 0 sps
1 nc
T F dt
T c
%%IncludeResource: font Courier
/_F0 /VIM-latin1 /Courier ref
/F0 10 /_F0 ffs
%%IncludeResource: font Courier-Bold
/_F1 /VIM-latin1 /Courier-Bold ref
/F1 10 /_F1 ffs
%%IncludeResource: font Courier-Oblique
/_F2 /VIM-latin1 /Courier-Oblique ref
/F2 10 /_F2 ffs
%%IncludeResource: font Courier-BoldOblique
/_F3 /VIM-latin1 /Courier-BoldOblique ref
/F3 10 /_F3 ffs
/UO -1 d
/UW 0.5 d
/BO -2.5 d
%%EndSetup
%%Page: 1 1
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(HW2//spirals.py                                                               Page 1)59.5 792.4 ms
F0 sf
0.753 0 0 r
(#!/bin/env python)59.5 772.4 ms
0.753 0 0.753 r
(import)59.5 752.4 ms
0 g
( tensorflow )s
0 0.502 0 r
(as)s
0 g
( tf)s
0.753 0 0.753 r
(from)59.5 742.4 ms
0 g
( sklearn.inspection )s
0.753 0 0.753 r
(import)s
0 g
( DecisionBoundaryDisplay)s
0 0.502 0 r
(class)59.5 722.4 ms
0 g
( )s
0.502 0.502 0 r
(Linear)s
0 g
(\(tf.Module\):)s
(    )59.5 712.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__init__)s
0 g
(\(self, num_inputs, num_outputs, bias=)s
0.502 0.502 0 r
(True)s
0 g
(\):)s
(        rng = tf.random.get_global_generator\(\))59.5 702.4 ms
(        stddev = tf.math.sqrt\()59.5 682.4 ms
0 0 0.753 r
(2)s
0 g
( / \(num_inputs + num_outputs\)\))s
(        self.w = tf.Variable\()59.5 662.4 ms
(            rng.normal\(shape=[num_inputs, num_outputs], stddev=stddev\),)59.5 652.4 ms
(            trainable=)59.5 642.4 ms
0.502 0.502 0 r
(True)s
0 g
(,)s
(            name=)59.5 632.4 ms
0 0 0.753 r
("Linear/w")s
0 g
(,)s
(        \))59.5 622.4 ms
(        self.bias = bias)59.5 602.4 ms
(        )59.5 582.4 ms
0 0.502 0 r
(if)s
0 g
( self.bias:)s
(            self.b = tf.Variable\()59.5 572.4 ms
(                tf.zeros\()59.5 562.4 ms
(                    shape=[)59.5 552.4 ms
0 0 0.753 r
(1)s
0 g
(, num_outputs],)s
(                \),)59.5 542.4 ms
(                trainable=)59.5 532.4 ms
0.502 0.502 0 r
(True)s
0 g
(,)s
(                name=)59.5 522.4 ms
0 0 0.753 r
("Linear/b")s
0 g
(,)s
(            \))59.5 512.4 ms
(    )59.5 492.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__call__)s
0 g
(\(self, x\):)s
(        z = x @ self.w)59.5 482.4 ms
(        )59.5 462.4 ms
0 0.502 0 r
(if)s
0 g
( self.bias:)s
(            z += self.b)59.5 452.4 ms
(        )59.5 432.4 ms
0 0.502 0 r
(return)s
0 g
( z)s
0 0.502 0 r
(class)59.5 412.4 ms
0 g
( )s
0.502 0.502 0 r
(MLP)s
0 g
(\(tf.Module\):)s
(    )59.5 402.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__init__)s
0 g
(\(self, num_inputs, num_outputs, num_hidden_layers, hidden_layer_widt)s
(h, hidden_activation = tf.identity, output_activation = tf.identity, bias=)59.5 392.4 ms
0.502 0.502 0 r
(True)s
0 g
(\):)s
(        self.num_inputs = num_inputs)59.5 382.4 ms
(        self.num_outputs = num_outputs)59.5 372.4 ms
(        self.num_hidden_layers = num_hidden_layers)59.5 362.4 ms
(        self.hidden_layer_width = hidden_layer_width)59.5 352.4 ms
(        self.hidden_activation = hidden_activation)59.5 342.4 ms
(        self.output_activation = output_activation)59.5 332.4 ms
(        rng = tf.random.get_global_generator\(\))59.5 312.4 ms
(        self.bias = bias)59.5 302.4 ms
(        )59.5 292.4 ms
0.753 0 0 r
(# weights were getting too large so I squashed them down by adding hidden_la)s
(yer_width)59.5 282.4 ms
0 g
(        )59.5 272.4 ms
0.753 0 0 r
(# stddev = tf.math.sqrt\(2 / \(hidden_layer_width\)\))s
0 g
(        self.input_layer = Linear\(num_inputs, hidden_layer_width\))59.5 252.4 ms
(        )59.5 232.4 ms
0.753 0 0 r
(# self.w = tf.Variable\()s
0 g
(        )59.5 222.4 ms
0.753 0 0 r
(#     rng.normal\(shape=[hidden_layer_width, hidden_layer_width, num_hidden_l)s
(ayers-1], stddev=stddev\),)59.5 212.4 ms
0 g
(        )59.5 202.4 ms
0.753 0 0 r
(#     trainable=True,)s
0 g
(        )59.5 192.4 ms
0.753 0 0 r
(#     name="MLP/w",)s
0 g
(        )59.5 182.4 ms
0.753 0 0 r
(# \))s
0 g
(        self.hidden_layers = [Linear\(hidden_layer_width, hidden_layer_width\) )59.5 162.4 ms
0 0.502 0 r
(for)s
0 g
( i )s
0 0.502 0 r
(i)s
(n)59.5 152.4 ms
0 g
( )s
0.502 0.502 0 r
(range)s
0 g
(\(num_hidden_layers\)])s
(        self.output_layer = Linear\(hidden_layer_width, num_outputs\))59.5 132.4 ms
(        )59.5 112.4 ms
0.753 0 0 r
(# if self.bias:)s
0 g
(        )59.5 102.4 ms
0.753 0 0 r
(#     self.b = tf.Variable\()s
0 g
(        )59.5 92.4 ms
0.753 0 0 r
(#         tf.zeros\()s
0 g
(        )59.5 82.4 ms
0.753 0 0 r
(#             shape=[1, num_hidden_layers],)s
0 g
(        )59.5 72.4 ms
0.753 0 0 r
(#         \),)s
0 g
(        )59.5 62.4 ms
0.753 0 0 r
(#         trainable=True,)s
0 g
(        )59.5 52.4 ms
0.753 0 0 r
(#         name="MLP/b",)s
re sp
%%PageTrailer
%%Page: 2 2
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(HW2//spirals.py                                                               Page 2)59.5 792.4 ms
F0 sf
(        )59.5 772.4 ms
0.753 0 0 r
(#     \))s
0 g
(    )59.5 752.4 ms
0 0.502 0 r
(def)s
0 g
( )s
0.502 0.502 0 r
(__call__)s
0 g
(\(self, x\):)s
(        z = tf.cast\(x, )59.5 742.4 ms
0 0 0.753 r
('float32')s
0 g
(\))s
(        z = tf.transpose\(z\))59.5 732.4 ms
(        )59.5 722.4 ms
0.753 0 0 r
(# z = tf.reshape\(z, [-1, 2]\))s
0 g
(        )59.5 712.4 ms
0.753 0 0 r
(# Iterate through the hidden layers)s
0 g
(        )59.5 702.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        z = self.input_layer\(z\))59.5 692.4 ms
(        )59.5 682.4 ms
0.753 0 0 r
(# z = tf.add\(z, tf.slice\(self.b, [0, 0], [1, 1]\)\))s
0 g
(        )59.5 672.4 ms
(        )59.5 662.4 ms
0 0.502 0 r
(for)s
0 g
( layer )s
0 0.502 0 r
(in)s
0 g
( )s
0.502 0.502 0 r
(range)s
0 g
(\(self.num_hidden_layers\):)s
(            )59.5 652.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(            )59.5 642.4 ms
0.753 0 0 r
(# z = tf.tensordot\(z, tf.slice\(self.w, [0, 0, layer+1], [self.hidden_lay)s
(er_width, self.hidden_layer_width, 1]\), axes = \(\(0\), \(1\)\)\) )59.5 632.4 ms
0 g
(            )59.5 622.4 ms
(            )59.5 612.4 ms
0.753 0 0 r
(# z =  z @ tf.slice\(self.w, [0, 0, layer], [self.hidden_layer_width, sel)s
(f.hidden_layer_width, 1]\))59.5 602.4 ms
0 g
(            )59.5 592.4 ms
0.753 0 0 r
(# z = tf.transpose\(z\))s
0 g
(            )59.5 582.4 ms
0.753 0 0 r
(# if self.bias:)s
0 g
(            )59.5 572.4 ms
0.753 0 0 r
(#     # breakpoint\(\))s
0 g
(            )59.5 562.4 ms
0.753 0 0 r
(#     z = tf.add\(z, tf.slice\(self.b, [0, layer+1], [1, 1]\)\))s
0 g
(            )59.5 552.4 ms
0.753 0 0 r
(# z = self.hidden_activation\(z\))s
0 g
(            z = self.hidden_activation\(self.hidden_layers[layer]\(z\)\))59.5 542.4 ms
(        )59.5 532.4 ms
0.753 0 0 r
(# ouptut layer)s
0 g
(        )59.5 522.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        p = self.output_activation\(self.output_layer\(z\)\))59.5 512.4 ms
(        )59.5 492.4 ms
0.753 0 0 r
(# if p >= 0.5:)s
0 g
(        )59.5 482.4 ms
0.753 0 0 r
(#     return 1)s
0 g
(        )59.5 472.4 ms
0.753 0 0 r
(# if p < 0.5:)s
0 g
(        )59.5 462.4 ms
0.753 0 0 r
(#     return 0)s
0 g
(        )59.5 452.4 ms
0 0.502 0 r
(return)s
0 g
( p)s
0 0.502 0 r
(def)59.5 432.4 ms
0 g
( )s
0.502 0.502 0 r
(grad_update)s
0 g
(\(step_size, variables, grads\):)s
(    )59.5 422.4 ms
0 0.502 0 r
(for)s
0 g
( var, grad )s
0 0.502 0 r
(in)s
0 g
( )s
0.502 0.502 0 r
(zip)s
0 g
(\(variables, grads\):)s
(        )59.5 412.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        var.assign_sub\(step_size * grad\))59.5 402.4 ms
0 0.502 0 r
(if)59.5 362.4 ms
0 g
( __name__ == )s
0 0 0.753 r
("__main__")s
0 g
(:)s
(    )59.5 352.4 ms
0.753 0 0.753 r
(import)s
0 g
( argparse)s
(    )59.5 342.4 ms
0.753 0 0.753 r
(import)s
0 g
( numpy )s
0 0.502 0 r
(as)s
0 g
( np)s
(    )59.5 332.4 ms
0.753 0 0.753 r
(from)s
0 g
( pathlib )s
0.753 0 0.753 r
(import)s
0 g
( Path)s
(    )59.5 312.4 ms
0.753 0 0.753 r
(import)s
0 g
( matplotlib.pyplot )s
0 0.502 0 r
(as)s
0 g
( plt)s
(    )59.5 302.4 ms
0.753 0 0.753 r
(import)s
0 g
( yaml)s
(    )59.5 282.4 ms
0.753 0 0.753 r
(from)s
0 g
( tqdm )s
0.753 0 0.753 r
(import)s
0 g
( trange)s
(    parser = argparse.ArgumentParser\()59.5 262.4 ms
(        prog=)59.5 252.4 ms
0 0 0.753 r
("Linear")s
0 g
(,)s
(        description=)59.5 242.4 ms
0 0 0.753 r
("Fits a linear model to some data, given a config")s
0 g
(,)s
(    \))59.5 232.4 ms
(    parser.add_argument\()59.5 212.4 ms
0 0 0.753 r
("-c")s
0 g
(, )s
0 0 0.753 r
("--config")s
0 g
(, )s
0.502 0.502 0 r
(type)s
0 g
(=Path, default=Path\()s
0 0 0.753 r
("config.yaml")s
0 g
(\)\))s
(    args = parser.parse_args\(\))59.5 202.4 ms
(    config = yaml.safe_load\(args.config.read_text\(\)\))59.5 182.4 ms
(    rng = tf.random.get_global_generator\(\))59.5 162.4 ms
(    rng.reset_from_seed\()59.5 152.4 ms
0 0 0.753 r
(0x43966E87BD57227011B5B03B58785EC1)s
0 g
(\))s
(    num_samples = config[)59.5 132.4 ms
0 0 0.753 r
("data")s
0 g
(][)s
0 0 0.753 r
("num_samples")s
0 g
(])s
(    num_inputs = )59.5 122.4 ms
0 0 0.753 r
(2)s
0 g
(    num_outputs = )59.5 112.4 ms
0 0 0.753 r
(1)s
0 g
(    random = np.random.default_rng\(\))59.5 92.4 ms
(    theta = random.uniform\(np.pi/)59.5 82.4 ms
0 0 0.753 r
(2)s
0 g
(, )s
0 0 0.753 r
(6)s
0 g
(*np.pi, )s
0.502 0.502 0 r
(int)s
0 g
(\(num_samples/)s
0 0 0.753 r
(2)s
0 g
(\)\))s
(    r = theta)59.5 72.4 ms
(    var =  config[)59.5 62.4 ms
0 0 0.753 r
("data")s
0 g
(][)s
0 0 0.753 r
("noise_stddev")s
0 g
(])s
(    noise = random.normal\()59.5 52.4 ms
0 0 0.753 r
(0)s
0 g
(, var, [)s
0 0 0.753 r
(2)s
0 g
(, num_samples]\))s
re sp
%%PageTrailer
%%Page: 3 3
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(HW2//spirals.py                                                               Page 3)59.5 792.4 ms
F0 sf
(    x0 = r * np.cos\(theta\))59.5 762.4 ms
(    y0 = r * np.sin\(theta\))59.5 752.4 ms
(    x1 = -r * np.cos\(theta\))59.5 732.4 ms
(    y1 = -r * np.sin\(theta\))59.5 722.4 ms
(    coords = np.array\([np.concatenate\(\(x0, x1\)\), np.concatenate\(\(y0, y1\)\)]\))59.5 702.4 ms
(    coords = coords + noise)59.5 692.4 ms
(    )59.5 682.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(    inputs = coords)59.5 672.4 ms
(    output_classes = np.zeros\([)59.5 662.4 ms
0 0 0.753 r
(1)s
0 g
(, num_samples]\))s
(    midpoint = )59.5 652.4 ms
0.502 0.502 0 r
(int)s
0 g
(\(output_classes.shape[)s
0 0 0.753 r
(1)s
0 g
(]/)s
0 0 0.753 r
(2)s
0 g
(\))s
(    output_classes = np.vstack\(\(np.zeros\([)59.5 642.4 ms
0 0 0.753 r
(1)s
0 g
(, )s
0.502 0.502 0 r
(int)s
0 g
(\(num_samples/)s
0 0 0.753 r
(2)s
0 g
(\)]\), np.ones\([)s
0 0 0.753 r
(1)s
0 g
(, )s
0.502 0.502 0 r
(int)s
0 g
(\(n)s
(um_samples/)59.5 632.4 ms
0 0 0.753 r
(2)s
0 g
(\)]\)\)\).reshape\([)s
0 0 0.753 r
(1)s
0 g
(, -)s
0 0 0.753 r
(1)s
0 g
(]\))s
(    )59.5 622.4 ms
0.753 0 0 r
(# linear = Linear\(num_inputs, num_outputs\))s
0 g
(    )59.5 612.4 ms
(    num_iters = config[)59.5 592.4 ms
0 0 0.753 r
("learning")s
0 g
(][)s
0 0 0.753 r
("num_iters")s
0 g
(])s
(    step_size = config[)59.5 582.4 ms
0 0 0.753 r
("learning")s
0 g
(][)s
0 0 0.753 r
("step_size")s
0 g
(])s
(    decay_rate = config[)59.5 572.4 ms
0 0 0.753 r
("learning")s
0 g
(][)s
0 0 0.753 r
("decay_rate")s
0 g
(])s
(    batch_size = config[)59.5 562.4 ms
0 0 0.753 r
("learning")s
0 g
(][)s
0 0 0.753 r
("batch_size")s
0 g
(])s
(    num_hidden_layers = config[)59.5 552.4 ms
0 0 0.753 r
("mlp")s
0 g
(][)s
0 0 0.753 r
("num_hidden_layers")s
0 g
(])s
(    hidden_layer_width = config[)59.5 542.4 ms
0 0 0.753 r
("mlp")s
0 g
(][)s
0 0 0.753 r
("hidden_layer_width")s
0 g
(])s
(    refresh_rate = config[)59.5 522.4 ms
0 0 0.753 r
("display")s
0 g
(][)s
0 0 0.753 r
("refresh_rate")s
0 g
(])s
(    mlp = MLP\(num_inputs, num_outputs, num_hidden_layers, hidden_layer_width, tf.nn.)59.5 512.4 ms
(relu, tf.nn.sigmoid\))59.5 502.4 ms
(    bar = trange\(num_iters\))59.5 492.4 ms
(    )59.5 482.4 ms
0.753 0 0 r
(# Initialize 1st and 2nd moment vectors)s
0 g
(    m = [tf.zeros\(mlp.trainable_variables[i].shape, dtype = )59.5 472.4 ms
0 0 0.753 r
('float32')s
0 g
(\) )s
0 0.502 0 r
(for)s
0 g
( i )s
0 0.502 0 r
(in)s
0 g
( )s
0.502 0.502 0 r
(rang)s
(e)59.5 462.4 ms
0 g
(\()s
0.502 0.502 0 r
(len)s
0 g
(\(mlp.trainable_variables\)\)])s
(    v = [tf.zeros\(mlp.trainable_variables[i].shape, dtype = )59.5 452.4 ms
0 0 0.753 r
('float32')s
0 g
(\) )s
0 0.502 0 r
(for)s
0 g
( i )s
0 0.502 0 r
(in)s
0 g
( )s
0.502 0.502 0 r
(rang)s
(e)59.5 442.4 ms
0 g
(\()s
0.502 0.502 0 r
(len)s
0 g
(\(mlp.trainable_variables\)\)])s
(    )59.5 432.4 ms
0.753 0 0 r
(# Unless the weighting for the L2 penalty is this small, the algorithm cannot co)s
(nverge. It will instead find that loss is minimized by setting all weights to 0 and )59.5 422.4 ms
(guessing  0 every time)59.5 412.4 ms
0 g
(    gamma = )59.5 402.4 ms
0 0 0.753 r
(0.001)s
0 g
(    )59.5 392.4 ms
0 0.502 0 r
(for)s
0 g
( i )s
0 0.502 0 r
(in)s
0 g
( bar:)s
(        batch_indices = rng.uniform\()59.5 382.4 ms
(            shape=[batch_size], maxval=num_samples, dtype=tf.int32)59.5 372.4 ms
(        \))59.5 362.4 ms
(        )59.5 352.4 ms
0 0.502 0 r
(with)s
0 g
( tf.GradientTape\(\) )s
0 0.502 0 r
(as)s
0 g
( tape:)s
(            )59.5 342.4 ms
0.753 0 0 r
(# tape.watch\(mlp.b\))s
0 g
(            )59.5 332.4 ms
0.753 0 0 r
(# x_batch = tf.gather\(inputs[0, :], batch_indices\))s
0 g
(            )59.5 322.4 ms
0.753 0 0 r
(# y_batch = tf.gather\(inputs[1, :], batch_indices\))s
0 g
(            x_batch = tf.gather\(inputs, batch_indices, axis=)59.5 312.4 ms
0 0 0.753 r
(1)s
0 g
(\))s
(            y_batch = tf.gather\(output_classes, batch_indices, axis = )59.5 302.4 ms
0 0 0.753 r
(1)s
0 g
(\))s
(            y_batch = tf.cast\(y_batch, )59.5 292.4 ms
0 0 0.753 r
('float32')s
0 g
(\))s
(            y_hat = [])59.5 272.4 ms
(            )59.5 262.4 ms
0.753 0 0 r
(# for k in range\(tf.size\(y_batch\)\):)s
0 g
(            )59.5 252.4 ms
0.753 0 0 r
(#     # breakpoint\(\))s
0 g
(            )59.5 242.4 ms
0.753 0 0 r
(#     # y_hat[0, i] = mlp\(x_batch[:, i]\))s
0 g
(            )59.5 232.4 ms
0.753 0 0 r
(#     # breakpoint\(\))s
0 g
(            )59.5 222.4 ms
0.753 0 0 r
(#     y_hat.append\(mlp\(x_batch[:, k]\)\))s
0 g
(            )59.5 212.4 ms
0.753 0 0 r
(# # breakpoint\(\))s
0 g
(            )59.5 202.4 ms
0.753 0 0 r
(# y_hat = tf.stack\(y_hat\))s
0 g
(            y_hat = mlp\(x_batch\))59.5 192.4 ms
(            )59.5 182.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(            )59.5 172.4 ms
0.753 0 0 r
(# loss = tf.norm\(\(tf.reshape\(mlp.w, [1, -1]\)\), ord = 'euclidean'\) - 1/ba)s
(tch_size * \(tf.tensordot\(y_batch, tf.math.log\(y_hat+\(1e-7\)\), axes = \(\(1\), \(0\)\)\)+ tf.)59.5 162.4 ms
(tensordot\(1-y_batch, tf.math.log\(1-y_hat+\(1e-7\)\), axes = \(\(1\), \(0\)\)\)\))59.5 152.4 ms
0 g
(            loss =  - )59.5 142.4 ms
0 0 0.753 r
(1)s
0 g
(/batch_size * \(tf.tensordot\(y_batch, tf.math.log\(y_hat+\()s
0 0 0.753 r
(1e-7)s
0 g
(\))s
(\), axes = \(\()59.5 132.4 ms
0 0 0.753 r
(1)s
0 g
(\), \()s
0 0 0.753 r
(0)s
0 g
(\)\)\)+ tf.tensordot\()s
0 0 0.753 r
(1)s
0 g
(-y_batch, tf.math.log\()s
0 0 0.753 r
(1)s
0 g
(-y_hat+\()s
0 0 0.753 r
(1e-7)s
0 g
(\)\), axes = \()s
(\()59.5 122.4 ms
0 0 0.753 r
(1)s
0 g
(\), \()s
0 0 0.753 r
(0)s
0 g
(\)\)\)\))s
(            )59.5 112.4 ms
0.753 0 0 r
(# add L2 regularization)s
0 g
(            )59.5 102.4 ms
0 0.502 0 r
(for)s
0 g
( var )s
0 0.502 0 r
(in)s
0 g
( mlp.trainable_variables:)s
(                loss += gamma* tf.math.reduce_sum\(tf.multiply\(tf.reshape\(var, [)59.5 92.4 ms
0 0 0.753 r
(1)s
0 g
(, -)s
0 0 0.753 r
(1)s
0 g
(]\), tf.reshape\(var, [)59.5 82.4 ms
0 0 0.753 r
(1)s
0 g
(, -)s
0 0 0.753 r
(1)s
0 g
(]\)\)\))s
(        )59.5 62.4 ms
0.753 0 0 r
(# print\(loss\))s
0 g
(        grads = tape.gradient\(loss, mlp.trainable_variables\))59.5 52.4 ms
re sp
%%PageTrailer
%%Page: 4 4
%%BeginPageSetup
sv
0 g
F0 sf
%%EndPageSetup
F1 sf
(HW2//spirals.py                                                               Page 4)59.5 792.4 ms
F0 sf
(        )59.5 772.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        )59.5 752.4 ms
0.753 0 0 r
(# Implementing Adam)s
0 g
(        beta_1 = )59.5 742.4 ms
0 0 0.753 r
(0.9)s
0 g
(        beta_2 = )59.5 732.4 ms
0 0 0.753 r
(0.999)s
0 g
(        )59.5 722.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        m = )59.5 712.4 ms
0.502 0.502 0 r
(tuple)s
0 g
(\()s
0.502 0.502 0 r
(map)s
0 g
(\()s
0.502 0.502 0 r
(sum)s
0 g
(, )s
0.502 0.502 0 r
(zip)s
0 g
(\()s
0.502 0.502 0 r
(tuple)s
0 g
(\([\(beta_1\)*m_i )s
0 0.502 0 r
(for)s
0 g
( m_i )s
0 0.502 0 r
(in)s
0 g
( m]\), )s
0.502 0.502 0 r
(tuple)s
0 g
(\([\()s
0 0 0.753 r
(1)s
0 g
(-beta_1\))s
(*grad )59.5 702.4 ms
0 0.502 0 r
(for)s
0 g
( grad )s
0 0.502 0 r
(in)s
0 g
( grads]\)\)\)\))s
(        grads_sq = [tf.math.multiply\(grad, grad\) )59.5 692.4 ms
0 0.502 0 r
(for)s
0 g
( grad )s
0 0.502 0 r
(in)s
0 g
( grads])s
(        v = )59.5 682.4 ms
0.502 0.502 0 r
(tuple)s
0 g
(\()s
0.502 0.502 0 r
(map)s
0 g
(\()s
0.502 0.502 0 r
(sum)s
0 g
(, )s
0.502 0.502 0 r
(zip)s
0 g
(\()s
0.502 0.502 0 r
(tuple)s
0 g
(\([\(beta_2\)*v_i )s
0 0.502 0 r
(for)s
0 g
( v_i )s
0 0.502 0 r
(in)s
0 g
( v]\), )s
0.502 0.502 0 r
(tuple)s
0 g
(\([\()s
0 0 0.753 r
(1)s
0 g
(-beta_2\))s
(*grad )59.5 672.4 ms
0 0.502 0 r
(for)s
0 g
( grad )s
0 0.502 0 r
(in)s
0 g
( grads_sq]\)\)\)\))s
(        )59.5 662.4 ms
(        m_hat = )59.5 652.4 ms
0.502 0.502 0 r
(tuple)s
0 g
(\([)s
0 0 0.753 r
(1)s
0 g
(/\()s
0 0 0.753 r
(1)s
0 g
(-beta_1**\(i+)s
0 0 0.753 r
(1)s
0 g
(\)\)*m_i )s
0 0.502 0 r
(for)s
0 g
( m_i )s
0 0.502 0 r
(in)s
0 g
( m]\))s
(        v_hat = )59.5 642.4 ms
0.502 0.502 0 r
(tuple)s
0 g
(\([)s
0 0 0.753 r
(1)s
0 g
(/\()s
0 0 0.753 r
(1)s
0 g
(-beta_2**\(i+)s
0 0 0.753 r
(1)s
0 g
(\)\)*v_i )s
0 0.502 0 r
(for)s
0 g
( v_i )s
0 0.502 0 r
(in)s
0 g
( v]\))s
(        grad_new = [tf.math.divide\(aItem, tf.math.sqrt\(bItem\)+\()59.5 622.4 ms
0 0 0.753 r
(1e-8)s
0 g
(\)\) )s
0 0.502 0 r
(for)s
0 g
( aItem, bIt)s
(em )59.5 612.4 ms
0 0.502 0 r
(in)s
0 g
( )s
0.502 0.502 0 r
(zip)s
0 g
(\(m_hat, v_hat\)])s
(        )59.5 602.4 ms
0.753 0 0 r
(# breakpoint\(\))s
0 g
(        grad_update\(step_size, mlp.trainable_variables, grad_new\))59.5 592.4 ms
(        )59.5 582.4 ms
(        )59.5 572.4 ms
0.753 0 0 r
(# grad_update\(step_size, mlp.trainable_variables, grads\))s
0 g
(        )59.5 562.4 ms
0.753 0 0 r
(# step_size *= decay_rate)s
0 g
(        )59.5 552.4 ms
0 0.502 0 r
(if)s
0 g
( i % refresh_rate == \(refresh_rate - )s
0 0 0.753 r
(1)s
0 g
(\):)s
(            bar.set_description\()59.5 542.4 ms
(                f)59.5 532.4 ms
0 0 0.753 r
("Step {i}; Loss => {loss.numpy\(\).squeeze\(\):0.4f}, step_size => {ste)s
(p_size:0.4f}")59.5 522.4 ms
0 g
(            \))59.5 512.4 ms
(            )59.5 502.4 ms
(            bar.refresh\(\))59.5 492.4 ms
(    fig, ax = plt.subplots\(\))59.5 472.4 ms
(    )59.5 462.4 ms
(   )59.5 452.4 ms
(    x, y = np.meshgrid\(np.linspace\(-)59.5 442.4 ms
0 0 0.753 r
(25.)s
0 g
(,)s
0 0 0.753 r
(25.)s
0 g
(, )s
0 0 0.753 r
(600)s
0 g
(\), np.linspace\(-)s
0 0 0.753 r
(25.)s
0 g
(,)s
0 0 0.753 r
(25.)s
0 g
(,)s
0 0 0.753 r
(600)s
0 g
(\)\))s
(    grid = np.vstack\([x.ravel\(\), y.ravel\(\)]\))59.5 432.4 ms
(    )59.5 422.4 ms
0.753 0 0 r
(# Reshape the x, y grid to fit a 2 x [-1] shape)s
0 g
(    y_pred = np.reshape\(mlp\(grid\), x.shape\))59.5 412.4 ms
(    display = DecisionBoundaryDisplay\()59.5 402.4 ms
(        xx0=x, xx1=y, response=y_pred)59.5 392.4 ms
(    \))59.5 382.4 ms
(    display.plot\(\))59.5 372.4 ms
(    display.ax_.scatter\(coords[)59.5 352.4 ms
0 0 0.753 r
(0)s
0 g
(, :], coords[)s
0 0 0.753 r
(1)s
0 g
(, :], c = output_classes, edgecolors=)s
0 0 0.753 r
(')s
(k')59.5 342.4 ms
0 g
(\))s
(    display.figure_.savefig\()59.5 322.4 ms
0 0 0.753 r
("plot.pdf")s
0 g
(\))s
re sp
%%PageTrailer
%%Trailer
%%Pages: 4
%%EOF
